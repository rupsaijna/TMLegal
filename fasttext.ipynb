{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d58c1a328e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext_data_tokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataset_for_category_fasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_fasttext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_metrics_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_soft_document_accuracy_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_metrics_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_chunk_and_doc_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_preds_and_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBinaryCUADDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/cuad_research/data_handling/fasttext_data_tokenization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# File includes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_data_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_dict_from_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_labels_for_document\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBinaryCUADDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Pip includes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/cuad_research/data_handling/data_tokenization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBinaryCUADDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# First load in train, valid, and test datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_handling.fasttext_data_tokenization import get_dataset_for_category_fasttext\n",
    "from metrics.metrics_fasttext import calculate_metrics_ft, calculate_soft_document_accuracy_ft, get_metrics_ft, calculate_chunk_and_doc_accuracy, get_preds_and_labels\n",
    "from data_handling.data import DocumentData, BinaryCUADDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fasttext\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_categories(categories):\n",
    "    for category in categories:\n",
    "        run(category)\n",
    "\n",
    "def run(category):\n",
    "    data_source = \"data/CUADv1.json\"\n",
    "    num_examples = 255 # 510 is max\n",
    "    subpart_size = 512\n",
    "    subpart_overlap = 26\n",
    "    data_destination = f\"data/binary_dataset_fasttext_{subpart_size}_{subpart_overlap}_{num_examples}.json\"\n",
    "    vocab_destination = f\"data/vocab_fasttext_{num_examples}.json\"\n",
    "    category = category\n",
    "    tokenize = spacy.load(\"en_core_web_sm\")\n",
    "    num_epochs = 1_000\n",
    "\n",
    "    train_dataset, test_dataset, tokenizer, vocab_to_idx = get_dataset_for_category_fasttext(category, data_source, data_destination, vocab_destination, num_examples, subpart_size, subpart_overlap, tokenize)\n",
    "    \n",
    "    \n",
    "    train_pd = pd.DataFrame(columns=[\"subpart\", \"label\"])\n",
    "\n",
    "    for doc in train_dataset:\n",
    "        for chunk in doc:\n",
    "            train_pd = train_pd.append({\"subpart\": chunk[\"subpart\"], \"label\": \"__label__\" + str(chunk[\"label\"])}, ignore_index=True)\n",
    "\n",
    "    train_pd[['subpart', 'label']].to_csv('train.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")\n",
    "    \n",
    "    \n",
    "    # Training the fastText classifier\n",
    "    print(\"Training for category:\", category)\n",
    "    model = fasttext.train_supervised('train.txt', wordNgrams = 2, epoch=num_epochs, lr=0.9)\n",
    "    \n",
    "    preds, labels = get_preds_and_labels(test_dataset, model)\n",
    "    \n",
    "    chunk_accuracy, document_accuracy = calculate_chunk_and_doc_accuracy(preds, labels)\n",
    "    soft_document_accuracy = calculate_soft_document_accuracy_ft(preds, labels)\n",
    "    metrics = get_metrics_ft(calculate_metrics_ft(preds, labels))\n",
    "    \n",
    "    results = {\"soft_doc_acc\": None, \"metrics\": None, \"chunk_acc\": None, \"doc_acc\": None}\n",
    "    \n",
    "    results[\"metrics\"] = metrics\n",
    "    results[\"soft_doc_acc\"] = soft_document_accuracy\n",
    "    results[\"chunk_acc\"] = chunk_accuracy\n",
    "    results[\"doc_acc\"] = document_accuracy\n",
    "    \n",
    "    with open(f\"./results/fasttext/{category}_{num_epochs}.json\", 'w') as fp:\n",
    "            json.dump(results, fp)\n",
    "            \n",
    "    model.save_model(f\"./models/fasttext/{category}_{num_epochs}.bin\")\n",
    "\n",
    "    print(\"Chunk accuracy:\", chunk_accuracy)\n",
    "    print(\"Document accuracy:\", document_accuracy)\n",
    "    print(\"Soft document accuracy:\", soft_document_accuracy)    \n",
    "    print(\"Metrics:\", metrics)\n",
    "    print()\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"expiration_date\", \"anti-assignment\", \"cap_on_liability\", \"license_grant\", \"effective_date\", \"audit_rights\", \"termination_for_convenience\"]\n",
    "categories_2 = [\"exclusivity\", \"renewal_term\", \"insurance\", \"revenueprofit_sharing\", \"volume_restriction\"]\n",
    "\n",
    "categories = categories + categories_2\n",
    "\n",
    "run_with_categories(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
